# Chain Validation Architecture

## Conceito: Economia MÃ¡xima de CrÃ©ditos

Sistema de validaÃ§Ã£o em cadeia que combina 2 modelos Gemini (Junior barato + Senior caro) para maximizar economia sem perder qualidade.

## Fluxo de ExecuÃ§Ã£o

```
User Question
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Junior LLM         â”‚  Gemini 2.0 Flash Lite
â”‚  - Gera resposta    â”‚  Custo: ~$0.0001/req
â”‚  - Self-confidence  â”‚  LatÃªncia: ~1s
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Confidence Check   â”‚  Threshold: 70%
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
    â”œâ”€ â‰¥70% â†’ Output (economia!)
    â”‚
    â””â”€ <70% â†’ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Senior LLM         â”‚  Gemini 2.5 Pro
              â”‚  - Valida resposta  â”‚  Custo: ~$0.001/req
              â”‚  - Corrige erros    â”‚  LatÃªncia: ~2s
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
              Final Output
```

## Componentes

### 1. JuniorLLMService
**Modelo:** Gemini 2.0 Flash Lite  
**FunÃ§Ã£o:** Gera resposta inicial + confidence score (0-100)

```python
{
  "response": {
    "content": "...",
    "explanation": "...",
    "edge_cases": "..."
  },
  "confidence": 85,
  "needs_validation": False
}
```

**CaracterÃ­sticas:**
- RÃ¡pido (~1s)
- Custo baixo (~$0.0001/req)
- Bom para perguntas simples/sintaxe

### 2. SeniorLLMService
**Modelo:** Gemini 2.5 Pro  
**FunÃ§Ã£o:** Valida e corrige resposta do Junior

```python
{
  "validated": True,
  "corrections": "Adicionei detalhes sobre...",
  "final_response": {
    "content": "...",
    "explanation": "...",
    "edge_cases": "..."
  }
}
```

**CaracterÃ­sticas:**
- Mais lento (~2s)
- Custo por requisiÃ§Ã£o (~$0.001)
- Excelente para debugging/arquitetura

### 3. ChainValidatorService
**FunÃ§Ã£o:** Orquestra Junior â†’ Senior baseado em confidence

**LÃ³gica:**
```python
if junior.confidence >= THRESHOLD:
    return junior.response  # Economia!
else:
    return senior.validate(junior.response)
```

## Economia Esperada

### CenÃ¡rio Real (1000 perguntas/dia)

**Sem Chain Validation:**
- 1000 req Ã— $0.001 (Pro) = $1.00/dia
- $30/mÃªs

**Com Chain Validation (70% confidence threshold):**
- 700 req Junior Ã— $0.0001 = $0.07/dia
- 300 req Senior Ã— $0.001 = $0.30/dia
- Total: $0.37/dia = $11/mÃªs

**Economia: 63%** ğŸ‰

## ConfiguraÃ§Ã£o

### VariÃ¡veis de Ambiente
```bash
CONFIDENCE_THRESHOLD=70  # Ajustar conforme necessidade
GEMINI_API_KEY=sua-chave
```

### Tuning do Threshold
- **60%**: Mais economia, menos qualidade
- **70%**: Balanceado (recomendado)
- **80%**: Menos economia, mais qualidade

## Metadata de Resposta

Toda resposta inclui metadata para observabilidade:

```json
{
  "content": "...",
  "explanation": "...",
  "edge_cases": "...",
  "metadata": {
    "used_senior": false,
    "confidence": 85,
    "model": "llama3",
    "corrections": null
  }
}
```

## Testes

### Cobertura MÃ­nima: 85%

**Testes UnitÃ¡rios:**
- JuniorLLMService retorna confidence
- SeniorLLMService valida resposta
- ChainValidator decide corretamente

**Testes de IntegraÃ§Ã£o:**
- Mock Ollama + Mock Gemini
- Cache hit evita chamadas
- Fallbacks funcionam

**Testes E2E:**
- Fluxo completo com ambos modelos
- Economia real medida

## Monitoramento

### MÃ©tricas Importantes
- % de requisiÃ§Ãµes que usaram Senior
- Confidence mÃ©dio do Junior
- Economia estimada (tokens salvos)
- LatÃªncia por rota (Junior vs Senior)

### Alertas
- Se Senior > 40% das chamadas â†’ Ajustar threshold
- Se Junior confidence < 50 frequente â†’ Melhorar prompts

## PrÃ³ximos Passos

1. **A/B Testing**: Testar diferentes thresholds
2. **Dynamic Threshold**: Ajustar por tipo de pergunta
3. **Feedback Loop**: UsuÃ¡rio valida resposta â†’ treina threshold
4. **Tiers**: Free (sÃ³ Junior) vs Pro (Chain completo)

## ReferÃªncias

- [Google Gemini Models](https://ai.google.dev/gemini-api/docs/models/gemini)
- [Gemini Pricing](https://ai.google.dev/pricing)
